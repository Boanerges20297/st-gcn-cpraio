"""
ANÃLISE COMPARATIVA E RECOMENDAÃ‡ÃƒO FINAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Compara os resultados das AnÃ¡lises 1 e 2 e fornece recomendaÃ§Ã£o
para qual abordagem implementar ST-GCN com melhor viabilidade.

CritÃ©rios de decisÃ£o:
1. Qualidade dos dados (esparsidade, sinal)
2. PadrÃµes espacio-temporais (autocorrelaÃ§Ã£o, estacionariedade)
3. Complexidade vs. ganho informativo
4. ValidaÃ§Ã£o cruzada esperada
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
from tabulate import tabulate

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. CARREGAR RESULTADOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_analysis_results():
    """Carrega resultados das duas anÃ¡lises."""
    print("[1] Carregando resultados das anÃ¡lises...")
    
    base_path = Path(__file__).parent.parent
    
    analysis_1_dir = base_path / "01_apenas_ocorrencias"
    analysis_2_dir = base_path / "02_ocorrencias_prisoes"
    
    results = {}
    
    # AnÃ¡lise 1
    if (analysis_1_dir / "metadata_analise_1.json").exists():
        with open(analysis_1_dir / "metadata_analise_1.json", 'r') as f:
            results['analise_1'] = json.load(f)
        print("âœ… AnÃ¡lise 1 carregada")
    else:
        print("âŒ AnÃ¡lise 1 nÃ£o encontrada. Execute: python analise_01_dataset_builder.py")
    
    # AnÃ¡lise 2
    if (analysis_2_dir / "metadata_analise_2.json").exists():
        with open(analysis_2_dir / "metadata_analise_2.json", 'r') as f:
            results['analise_2'] = json.load(f)
        print("âœ… AnÃ¡lise 2 carregada")
    else:
        print("âŒ AnÃ¡lise 2 nÃ£o encontrada. Execute: python analise_02_dataset_builder.py")
    
    return results

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. EXTRAIR MÃ‰TRICAS-CHAVE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_metrics(results):
    """Extrai mÃ©tricas-chave para comparaÃ§Ã£o."""
    print("\n[2] Extraindo mÃ©tricas-chave...")
    
    comparison = {
        'MÃ©trica': [],
        'AnÃ¡lise 1 (Apenas CVLI)': [],
        'AnÃ¡lise 2 (CVLI + PrisÃµes)': [],
        'Melhor': []
    }
    
    # 1. DimensÃµes do tensor
    if 'analise_1' in results:
        a1 = results['analise_1']
        t1 = a1.get('n_timesteps', 'N/A')
        n1 = a1.get('n_nodes', 'N/A')
        f1 = a1.get('n_features', 'N/A')
    else:
        t1 = n1 = f1 = 'N/A'
    
    if 'analise_2' in results:
        a2 = results['analise_2']
        t2 = a2.get('n_timesteps', 'N/A')
        n2 = a2.get('n_nodes', 'N/A')
        f2 = a2.get('n_features', 'N/A')
    else:
        t2 = n2 = f2 = 'N/A'
    
    comparison['MÃ©trica'].append('Timesteps')
    comparison['AnÃ¡lise 1 (Apenas CVLI)'].append(str(t1))
    comparison['AnÃ¡lise 2 (CVLI + PrisÃµes)'].append(str(t2))
    comparison['Melhor'].append('â‰ˆ' if t1 == t2 else 'A1' if t1 > t2 else 'A2')
    
    comparison['MÃ©trica'].append('NÃ³s (bairros)')
    comparison['AnÃ¡lise 1 (Apenas CVLI)'].append(str(n1))
    comparison['AnÃ¡lise 2 (CVLI + PrisÃµes)'].append(str(n2))
    comparison['Melhor'].append('â‰ˆ' if n1 == n2 else 'A1' if n1 > n2 else 'A2')
    
    comparison['MÃ©trica'].append('Features')
    comparison['AnÃ¡lise 1 (Apenas CVLI)'].append(str(f1))
    comparison['AnÃ¡lise 2 (CVLI + PrisÃµes)'].append(str(f2))
    comparison['Melhor'].append('A2 (mais features)')
    
    # 2. Esparsidade
    if 'analise_1' in results:
        sparse_a1 = results['analise_1'].get('sparsity', 'N/A')
        if isinstance(sparse_a1, (int, float)):
            sparse_a1_pct = f"{sparse_a1*100:.1f}%"
        else:
            sparse_a1_pct = sparse_a1
    else:
        sparse_a1_pct = 'N/A'
    
    if 'analise_2' in results:
        sparse_a2_cvli = results['analise_2'].get('sparsity_cvli', 0)
        if isinstance(sparse_a2_cvli, (int, float)):
            sparse_a2_pct = f"{sparse_a2_cvli*100:.1f}%"
        else:
            sparse_a2_pct = 'N/A'
    else:
        sparse_a2_pct = 'N/A'
    
    comparison['MÃ©trica'].append('Esparsidade')
    comparison['AnÃ¡lise 1 (Apenas CVLI)'].append(sparse_a1_pct)
    comparison['AnÃ¡lise 2 (CVLI + PrisÃµes)'].append(sparse_a2_pct)
    comparison['Melhor'].append('A2 (mais dados)' if float(sparse_a2_cvli or 0) < float(sparse_a1 or 1) else 'A1')
    
    # 3. Total de eventos
    if 'analise_1' in results:
        total_a1 = results['analise_1'].get('total_cvli', 'N/A')
    else:
        total_a1 = 'N/A'
    
    if 'analise_2' in results:
        total_cvli_a2 = results['analise_2'].get('total_cvli', 0)
        total_pris_a2 = results['analise_2'].get('total_prisoes', 0)
        total_a2_str = f"CVLI: {int(total_cvli_a2)}, Pris: {int(total_pris_a2)}"
    else:
        total_a2_str = 'N/A'
    
    comparison['MÃ©trica'].append('Total de eventos')
    comparison['AnÃ¡lise 1 (Apenas CVLI)'].append(str(int(total_a1) if total_a1 != 'N/A' else 'N/A'))
    comparison['AnÃ¡lise 2 (CVLI + PrisÃµes)'].append(total_a2_str)
    comparison['Melhor'].append('A2 (mais contexto)')
    
    # 4. Estacionariedade
    if 'analise_1' in results and 'stationary_nodes_pct' in results['analise_1'].get('temporal_autocorr', {}):
        stat_a1 = results['analise_1']['temporal_autocorr']['stationary_nodes_pct']
        stat_a1_str = f"{stat_a1:.1f}%"
    else:
        stat_a1_str = 'N/A'
    
    if 'analise_2' in results:
        stat_a2_str = 'AnÃ¡lise completa'
    else:
        stat_a2_str = 'N/A'
    
    comparison['MÃ©trica'].append('Estacionariedade')
    comparison['AnÃ¡lise 1 (Apenas CVLI)'].append(stat_a1_str)
    comparison['AnÃ¡lise 2 (CVLI + PrisÃµes)'].append(stat_a2_str)
    comparison['Melhor'].append('âœ“ Ambas')
    
    # 5. CorrelaÃ§Ã£o informativa
    if 'analise_2' in results and 'lag_effects' in results['analise_2']:
        neg_corr = results['analise_2']['lag_effects'].get('negative_correlation_pct', 0)
        corr_a2_str = f"{neg_corr:.1f}% com correlaÃ§Ã£o negativa (eficaz)"
    else:
        corr_a2_str = 'N/A'
    
    comparison['MÃ©trica'].append('CorrelaÃ§Ã£o CVLI-PrisÃµes')
    comparison['AnÃ¡lise 1 (Apenas CVLI)'].append('N/A (sem prisÃµes)')
    comparison['AnÃ¡lise 2 (CVLI + PrisÃµes)'].append(corr_a2_str)
    comparison['Melhor'].append('A2')
    
    return pd.DataFrame(comparison)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. SCORING E RECOMENDAÃ‡ÃƒO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def calculate_scores(results):
    """Calcula score de viabilidade para cada anÃ¡lise."""
    print("\n[3] Calculando scores de viabilidade...")
    
    scores = {'analise_1': {}, 'analise_2': {}}
    
    # AnÃ¡lise 1
    if 'analise_1' in results:
        a1 = results['analise_1']
        
        # Fator esparsidade (menos Ã© melhor)
        sparse_a1 = a1.get('sparsity', 0.5)
        sparsity_score_a1 = max(0, 100 - sparse_a1 * 100 * 2)
        
        # Fator estacionariedade
        stat_a1 = a1.get('temporal_autocorr', {}).get('stationary_nodes_pct', 40)
        stat_score_a1 = stat_a1
        
        # Fator signal-to-noise
        mean_a1 = a1.get('mean', 0)
        std_a1 = a1.get('std', 1)
        snr_a1 = (mean_a1 / max(std_a1, 0.01)) * 10
        signal_score_a1 = min(100, snr_a1)
        
        scores['analise_1'] = {
            'sparsity': sparsity_score_a1,
            'stationarity': stat_score_a1,
            'signal': signal_score_a1,
            'features': 33,  # 1 feature
            'overall': (sparsity_score_a1 * 0.35 + stat_score_a1 * 0.35 + signal_score_a1 * 0.2 + 33 * 0.1)
        }
    
    # AnÃ¡lise 2
    if 'analise_2' in results:
        a2 = results['analise_2']
        
        # Esparsidade mÃ©dia
        sparse_cvli = a2.get('sparsity_cvli', 0.5)
        sparse_pris = a2.get('sparsity_pris', 0.5)
        sparse_avg = (sparse_cvli + sparse_pris) / 2
        sparsity_score_a2 = max(0, 100 - sparse_avg * 100 * 2)
        
        # CorrelaÃ§Ã£o informativa
        neg_corr = a2.get('lag_effects', {}).get('negative_correlation_pct', 30)
        corr_score_a2 = min(100, neg_corr * 2)  # Quanto mais negativa, melhor
        
        # Features
        feature_score_a2 = 75  # 3 features
        
        scores['analise_2'] = {
            'sparsity': sparsity_score_a2,
            'correlation': corr_score_a2,
            'features': feature_score_a2,
            'overall': (sparsity_score_a2 * 0.35 + corr_score_a2 * 0.35 + feature_score_a2 * 0.3)
        }
    
    return scores

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. GERAR RELATÃ“RIO COMPARATIVO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_comparative_report(results, comparison_df, scores):
    """Gera relatÃ³rio comparativo final."""
    print("\n[4] Gerando relatÃ³rio comparativo...")
    
    lines = [
        "# ANÃLISE COMPARATIVA: QUAL ABORDAGEM Ã‰ MAIS VIÃVEL?",
        "=" * 80,
        "",
        "## ğŸ“Š COMPARAÃ‡ÃƒO DE DADOS",
        "",
        "### Tabela Comparativa",
        "",
        tabulate(comparison_df, headers='keys', tablefmt='github', showindex=False),
        "",
        "",
        "## ğŸ¯ SCORING DE VIABILIDADE (0-100)",
        "",
        "### AnÃ¡lise 1: Apenas OcorrÃªncias (CVLI)",
        "",
    ]
    
    if 'analise_1' in scores:
        s1 = scores['analise_1']
        lines.extend([
            f"- **Esparsidade:** {s1.get('sparsity', 0):.1f}/100",
            f"  â†’ Capacidade de ter dados significativos",
            f"- **Estacionariedade:** {s1.get('stationarity', 0):.1f}/100",
            f"  â†’ Previsibilidade temporal",
            f"- **Sinal-to-Noise:** {s1.get('signal', 0):.1f}/100",
            f"  â†’ Clareza do padrÃ£o vs ruÃ­do",
            f"- **Riqueza de Features:** {s1.get('features', 0):.1f}/100",
            f"  â†’ InformaÃ§Ã£o disponÃ­vel (1 feature apenas)",
            "",
            f"### **SCORE GERAL: {s1.get('overall', 0):.1f}/100**",
            "",
        ])
    
    lines.append("### AnÃ¡lise 2: OcorrÃªncias + PrisÃµes (Features Cruzadas)")
    lines.append("")
    
    if 'analise_2' in scores:
        s2 = scores['analise_2']
        lines.extend([
            f"- **Esparsidade:** {s2.get('sparsity', 0):.1f}/100",
            f"  â†’ DistribuiÃ§Ã£o de dados entre 2 sÃ©ries",
            f"- **CorrelaÃ§Ã£o Informativa:** {s2.get('correlation', 0):.1f}/100",
            f"  â†’ RelaÃ§Ã£o entre prisÃµes e CVLI (causalidade potencial)",
            f"- **Riqueza de Features:** {s2.get('features', 0):.1f}/100",
            f"  â†’ InformaÃ§Ã£o disponÃ­vel (3 features + contexto)",
            "",
            f"### **SCORE GERAL: {s2.get('overall', 0):.1f}/100**",
            "",
        ])
    
    # DecisÃ£o final
    if 'analise_1' in scores and 'analise_2' in scores:
        score_1 = scores['analise_1']['overall']
        score_2 = scores['analise_2']['overall']
        
        lines.append("## ğŸ† RECOMENDAÃ‡ÃƒO FINAL")
        lines.append("")
        
        if score_2 > score_1 + 10:
            lines.extend([
                f"### **âœ… RECOMENDAÃ‡ÃƒO: ANÃLISE 2 (OCORRÃŠNCIAS + PRISÃ•ES)**",
                "",
                f"**Score AnÃ¡lise 2: {score_2:.1f}/100** > **Score AnÃ¡lise 1: {score_1:.1f}/100**",
                "",
                "#### Por que AnÃ¡lise 2 Ã© melhor?",
                "",
                "1. **Mais contexto informativo**",
                "   - 3 features vs 1 feature",
                "   - Captura relaÃ§Ã£o causal (prisÃµes â†’ CVLI)",
                "",
                "2. **CorrelaÃ§Ã£o CVLI-PrisÃµes revela padrÃµes**",
                "   - Bairros onde operaÃ§Ãµes sÃ£o eficazes",
                "   - Bairros onde operaÃ§Ãµes nÃ£o funcionam",
                "   - Permite aprendizado de tÃ¡ticas",
                "",
                "3. **Melhor para previsÃ£o de CVLI**",
                "   - Contexto operacional ajuda o modelo",
                "   - Reduz ambiguidade de padrÃµes",
                "",
                "#### Como implementar?",
                "",
                "```bash",
                "cd teste_modelo/02_ocorrencias_prisoes/",
                "python analise_02_dataset_builder.py",
                "# Usar tensor_ocorrencias_prisoes.npy para treinar ST-GCN",
                "```",
                "",
            ])
        
        elif score_1 > score_2 + 10:
            lines.extend([
                f"### **âœ… RECOMENDAÃ‡ÃƒO: ANÃLISE 1 (APENAS OCORRÃŠNCIAS)**",
                "",
                f"**Score AnÃ¡lise 1: {score_1:.1f}/100** > **Score AnÃ¡lise 2: {score_2:.1f}/100**",
                "",
                "#### Por que AnÃ¡lise 1 Ã© melhor?",
                "",
                "1. **Menos ruÃ­do de confundimento**",
                "   - Apenas o fenÃ´meno de interesse",
                "   - Sem variÃ¡veis confundidoras",
                "",
                "2. **Baseline mais limpo**",
                "   - Facilita interpretaÃ§Ã£o",
                "   - Reduz overfitting",
                "",
            ])
        
        else:
            lines.extend([
                f"### **âš ï¸ RECOMENDAÃ‡ÃƒO: IMPLEMENTAR AMBAS (com preferÃªncia em AnÃ¡lise 2)**",
                "",
                f"**Score AnÃ¡lise 1: {score_1:.1f}/100** vs **Score AnÃ¡lise 2: {score_2:.1f}/100**",
                "",
                "#### EstratÃ©gia hÃ­brida:",
                "",
                "1. **Phase 1**: Treinar modelo com AnÃ¡lise 2",
                "   - Aproveita melhor a informaÃ§Ã£o disponÃ­vel",
                "   - Valida efetividade de operaÃ§Ãµes",
                "",
                "2. **Phase 2**: Comparar com modelo AnÃ¡lise 1",
                "   - Identifica quanto prisÃµes contribuem",
                "   - Evita overfitting por confundimento",
                "",
            ])
    
    lines.extend([
        "",
        "## ğŸ“‹ PRÃ“XIMOS PASSOS",
        "",
        "### 1. ValidaÃ§Ã£o Cruzada",
        "```python",
        "# Dividir 70% treino / 30% teste",
        "# Usar k-fold CV (k=5)",
        "# MÃ©trica: MAE, RMSE, RÂ²",
        "```",
        "",
        "### 2. Teste de Modelos Baseline",
        "```python",
        "# ARIMA para comparaÃ§Ã£o",
        "# Prophet para sazonalidade",
        "# RegressÃ£o Linear (baseline simples)",
        "```",
        "",
        "### 3. Ajuste de HiperparÃ¢metros ST-GCN",
        "```python",
        "# Hidden dimensions: 32, 64, 128",
        "# NÃºmero de layers: 2, 3, 4",
        "# Learning rate: 0.001, 0.01",
        "# Dropout: 0.2, 0.5",
        "```",
        "",
        "---",
    ])
    
    return "\n".join(lines)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    print("\n" + "="*80)
    print("ANÃLISE COMPARATIVA: QUAL ABORDAGEM Ã‰ MAIS VIÃVEL PARA ST-GCN?")
    print("="*80)
    
    # 1. Carregar resultados
    results = load_analysis_results()
    
    if not results:
        print("âŒ Nenhuma anÃ¡lise encontrada. Execute ambos os scripts primeiro:")
        print("   python teste_modelo/01_apenas_ocorrencias/analise_01_dataset_builder.py")
        print("   python teste_modelo/02_ocorrencias_prisoes/analise_02_dataset_builder.py")
        return
    
    # 2. Extrair comparaÃ§Ã£o
    comparison_df = extract_metrics(results)
    print("\nâœ… MÃ©tricas extraÃ­das")
    
    # 3. Calcular scores
    scores = calculate_scores(results)
    print("âœ… Scores calculados")
    
    # 4. Gerar relatÃ³rio
    report = generate_comparative_report(results, comparison_df, scores)
    
    # 5. Salvar
    output_dir = Path(__file__).parent
    report_path = output_dir / "RELATORIO_COMPARATIVO_FINAL.md"
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nâœ… RelatÃ³rio salvo: {report_path}")
    
    print("\n" + "="*80)
    print(report)
    print("="*80)

if __name__ == '__main__':
    main()
