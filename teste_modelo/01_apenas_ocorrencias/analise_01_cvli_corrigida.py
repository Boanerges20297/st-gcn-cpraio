"""
AN√ÅLISE 1 (CORRIGIDA): Viabilidade ST-GCN com CVLI-only (dados do IBGE com lat/long)
Dataset: outputs/cvli_with_bairro.csv filtrado para tipo='cvli' desde 2022
Features: Apenas CVLI (homic√≠dios/latroc√≠nios)
"""
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from scipy import stats

OUTPUT_DIR = Path("teste_modelo/01_apenas_ocorrencias")
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)

DATA_FILE = Path("outputs/cvli_with_bairro.csv")

print("\n" + "="*80)
print("AN√ÅLISE 1 (CORRIGIDA): VIABILIDADE ST-GCN CVLI-ONLY (TIPO=CVLI)")
print("="*80)

# 1. Carregar dados CVLI
print("\n[1] Carregando dados CVLI...")
df = pd.read_csv(DATA_FILE, low_memory=False)
df['data'] = pd.to_datetime(df['data'])

# Filtrar apenas CVLI desde 2022
df = df[(df['data'].dt.year >= 2022) & (df['tipo'].str.lower() == 'cvli')].copy()
print(f"   ‚úì {len(df):,} eventos CVLI (2022-2026)")
print(f"   ‚úì Per√≠odo: {df['data'].min().date()} a {df['data'].max().date()}")

# 2. Remover registros sem coordenadas
print("\n[2] Filtrando registros com coordenadas...")
df = df.dropna(subset=['latitude', 'longitude'])
print(f"   ‚úì {len(df):,} eventos CVLI com coordenadas ({(len(df)/df.shape[0]*100):.1f}%)")

# 3. Usar bairro_assigned (normalizado pelo projeto)
print("\n[3] Preparando dados geogr√°ficos...")
df_geo = df.dropna(subset=['bairro_assigned']).copy()
print(f"   ‚úì {len(df_geo):,} eventos com bairro normalizado ({(len(df_geo)/len(df)*100):.1f}%)")
print(f"   ‚úì Bairros √∫nicos: {df_geo['bairro_assigned'].nunique()}")

# 4. Construir matriz espacial (T √ó N)
print("\n[4] Construindo matriz temporal...")
dates = pd.date_range(df_geo['data'].min(), df_geo['data'].max(), freq='D')
T = len(dates)

# Agrupar bairros
bairros = df_geo['bairro_assigned'].unique()
N = len(bairros)
bairro_to_idx = {b: i for i, b in enumerate(bairros)}

print(f"   ‚úì Per√≠odo: {T} dias")
print(f"   ‚úì Bairros: {N}")
print(f"   ‚úì Dimens√µes: {T} √ó {N} = {T*N:,} c√©lulas")

# Construir matriz de contagem
matrix = np.zeros((T, N))
daily_totals = np.zeros(T)

for idx, row in df_geo.iterrows():
    t_idx = (row['data'].date() - dates[0].date()).days
    if 0 <= t_idx < T:
        n_idx = bairro_to_idx[row['bairro_assigned']]
        matrix[t_idx, n_idx] += 1
        daily_totals[t_idx] += 1

print(f"   ‚úì Matriz constru√≠da")

# 5. Calcular m√©tricas
print("\n[5] Calculando m√©tricas de viabilidade...")

# Esparsidade
nonzero = np.count_nonzero(matrix)
sparsity = 1 - (nonzero / matrix.size)
print(f"\n   üìä ESPARSIDADE")
print(f"      C√©lulas n√£o-vazias: {nonzero:,}/{matrix.size:,} ({(nonzero/matrix.size)*100:.2f}%)")
print(f"      Esparsidade: {sparsity*100:.2f}%")

# Sinal (intensidade m√©dia)
signal_mean = matrix.sum() / (T * N)
signal_nz = matrix[matrix > 0].mean() if nonzero > 0 else 0
print(f"\n   üîä SINAL (eventos/dia/bairro)")
print(f"      M√©dia geral: {signal_mean:.6f}")
print(f"      M√©dia (apenas c√©lulas com evento): {signal_nz:.4f}")
if nonzero > 0:
    p50 = np.percentile(matrix[matrix > 0], 50)
    p75 = np.percentile(matrix[matrix > 0], 75)
    p90 = np.percentile(matrix[matrix > 0], 90)
    print(f"      Distribui√ß√£o (c√©lulas com evento):")
    print(f"         P50: {p50:.2f}, P75: {p75:.2f}, P90: {p90:.2f}")

# Variabilidade temporal (coeficiente de varia√ß√£o)
valid_days = daily_totals[daily_totals > 0]
if len(valid_days) > 0:
    cv = valid_days.std() / valid_days.mean() if valid_days.mean() > 0 else 0
    print(f"\n   üìà VARIABILIDADE TEMPORAL")
    print(f"      Dias com eventos: {len(valid_days)}/{T} ({(len(valid_days)/T)*100:.1f}%)")
    print(f"      M√©dia (dias com evento): {valid_days.mean():.2f}")
    print(f"      Std: {valid_days.std():.2f}")
    print(f"      CV: {cv:.3f}")
    
    # Autocorrela√ß√£o temporal
    if len(valid_days) > 2:
        acf_lag1 = np.corrcoef(daily_totals[:-1], daily_totals[1:])[0, 1]
        acf_lag1_str = f"{acf_lag1:.3f}"
        print(f"      Autocorrela√ß√£o Lag-1: {acf_lag1_str}")
    else:
        acf_lag1_str = "N/A"
else:
    cv = 0
    acf_lag1_str = "N/A"
    print(f"\n   üìà VARIABILIDADE TEMPORAL: SEM EVENTOS")

# 6. Calcular viabilidade
print(f"\n   üéØ C√ÅLCULO DE VIABILIDADE")

# Score de esparsidade: alta esparsidade = ruim
score_sparsity = max(0, 100 - sparsity * 150)

# Score de sinal: quanto maior o sinal n√£o-zero, melhor
score_signal = min(100, signal_nz * 1000)

# Score de variabilidade: CV muito alto √© ruim (padr√£o inconsistente)
score_variability = max(0, 100 - abs(cv - 0.5) * 50)

# Score de cobertura: % de bairros com pelo menos 1 evento
bairros_with_events = np.sum(matrix.sum(axis=0) > 0)
score_coverage = (bairros_with_events / N) * 100

print(f"      Esparsidade: {score_sparsity:.1f}/100")
print(f"      Sinal (intensidade): {score_signal:.1f}/100")
print(f"      Variabilidade temporal: {score_variability:.1f}/100")
print(f"      Cobertura espacial: {score_coverage:.1f}/100")

overall_score = (score_sparsity * 0.25 + score_signal * 0.35 + 
                score_variability * 0.20 + score_coverage * 0.20)
print(f"      GERAL: {overall_score:.1f}/100")

# 7. Salvar tensor
print(f"\n[6] Salvando tensor e metadados...")
tensor_path = OUTPUT_DIR / "tensor_cvli_only_CORRIGIDO.npy"
np.save(tensor_path, matrix)
print(f"   ‚úÖ Tensor: {tensor_path}")

# 8. Gerar relat√≥rio
print(f"\n[7] Gerando relat√≥rio...")

report = f"""# AN√ÅLISE 1 (CORRIGIDA): VIABILIDADE ST-GCN CVLI-ONLY

## üìä Resumo Executivo

**Dataset:** outputs/cvli_with_bairro.csv filtrado (tipo='cvli')
**Per√≠odo:** {df_geo['data'].min().date()} a {df_geo['data'].max().date()} ({T} dias)
**Eventos CVLI:** {len(df_geo):,} 
**Cobertura geogr√°fica:** {N} bairros normalizados (Fortaleza + RMF + Interior)
**Dimens√µes do tensor:** T={T} √ó N={N} ‚Üí {T*N:,} c√©lulas

## üìà M√©tricas de Qualidade

### Esparsidade
- **C√©lulas n√£o-vazias:** {nonzero:,}/{matrix.size:,} ({(nonzero/matrix.size)*100:.2f}%)
- **Esparsidade:** {sparsity*100:.2f}%
- **Avalia√ß√£o:** {"‚úÖ √ìTIMA" if sparsity < 0.5 else "üü° BOM" if sparsity < 0.8 else "‚ö†Ô∏è CR√çTICO"}

### Sinal Temporal
- **Intensidade m√©dia (todas as c√©lulas):** {signal_mean:.6f} eventos/dia/bairro
- **Intensidade m√©dia (apenas c√©lulas com evento):** {signal_nz:.4f}
- **Avalia√ß√£o:** {"‚úÖ FORTE" if signal_nz > 0.1 else "üü° M√âDIO" if signal_nz > 0.01 else "‚ö†Ô∏è FRACO"}

### Variabilidade Temporal
- **Dias com eventos:** {len(valid_days)}/{T} ({(len(valid_days)/T)*100:.1f}%)
- **Coeficiente de Varia√ß√£o:** {cv:.3f}
- **Autocorrela√ß√£o (Lag-1):** {acf_lag1_str}
- **Avalia√ß√£o:** {"‚úÖ PREVIS√çVEL" if cv < 1.0 else "üü° MODERADO" if cv < 3.0 else "‚ö†Ô∏è CA√ìTICO"}

### Cobertura Espacial
- **Bairros com eventos:** {bairros_with_events}/{N} ({score_coverage:.1f}%)
- **Avalia√ß√£o:** {"‚úÖ EXCELENTE" if score_coverage > 80 else "üü° BOM" if score_coverage > 50 else "‚ö†Ô∏è FRACO"}

## üéØ Viabilidade ST-GCN

### Scoring (0-100)
| Aspecto | Score | Peso | Contribui√ß√£o |
|---------|-------|------|--------------|
| Esparsidade | {score_sparsity:.1f} | 25% | {score_sparsity*0.25:.1f} |
| Sinal (intensidade) | {score_signal:.1f} | 35% | {score_signal*0.35:.1f} |
| Variabilidade | {score_variability:.1f} | 20% | {score_variability*0.20:.1f} |
| Cobertura | {score_coverage:.1f} | 20% | {score_coverage*0.20:.1f} |
| **GERAL** | **{overall_score:.1f}** | 100% | **{overall_score:.1f}** |

### Recomenda√ß√£o
"""

if overall_score >= 75:
    report += f"**üü¢ ALTAMENTE VI√ÅVEL** - Score {overall_score:.1f}/100\n"
    report += "ST-GCN √© recomendado para implementa√ß√£o.\n"
elif overall_score >= 60:
    report += f"**üü° VI√ÅVEL** - Score {overall_score:.1f}/100\n"
    report += "ST-GCN pode funcionar com performance aceit√°vel.\n"
else:
    report += f"**üî¥ N√ÉO RECOMENDADO** - Score {overall_score:.1f}/100\n"
    report += "Dataset insuficiente. Considere enriquecer com features de contexto.\n"

report += f"""
## üìã Pr√≥ximos Passos

1. Comparar com An√°lise 2 (CVLI + Contexto Operacional)
2. Se score >= 60: Proceder com implementa√ß√£o
3. Valida√ß√£o cruzada com holdout (√∫ltimos 30 dias)
4. Tuning de hyperpar√¢metros do ST-GCN

---
**Data de gera√ß√£o:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Arquivo tensor:** tensor_cvli_only_CORRIGIDO.npy ({T} √ó {N})
**Fonte:** outputs/cvli_with_bairro.csv (tipo='cvli')
"""

report_path = OUTPUT_DIR / "RELATORIO_ANALISE_1_CORRIGIDA.md"
with open(report_path, 'w', encoding='utf-8') as f:
    f.write(report)
print(f"   ‚úÖ Relat√≥rio: {report_path}")

# 9. Salvar metadados
metadata = {
    'fonte': 'outputs/cvli_with_bairro.csv (tipo=cvli)',
    'periodo': f"{df_geo['data'].min().date()} a {df_geo['data'].max().date()}",
    'total_dias': int(T),
    'total_bairros': int(N),
    'eventos_cvli': int(len(df_geo)),
    'tensor_shape': [int(T), int(N)],
    'tensor_cells': int(T*N),
    'cells_nonzero': int(nonzero),
    'sparsity': float(sparsity),
    'signal_mean': float(signal_mean),
    'signal_nz_mean': float(signal_nz),
    'cv': float(cv),
    'score': {
        'sparsidade': float(score_sparsity),
        'sinal': float(score_signal),
        'variabilidade': float(score_variability),
        'cobertura': float(score_coverage),
        'geral': float(overall_score)
    }
}

metadata_path = OUTPUT_DIR / "metadata_analise_1_CORRIGIDA.json"
with open(metadata_path, 'w', encoding='utf-8') as f:
    json.dump(metadata, f, indent=2)
print(f"   ‚úÖ Metadados: {metadata_path}")

print("\n" + "="*80)
print(f"‚úÖ AN√ÅLISE 1 (CORRIGIDA) CONCLU√çDA - Score: {overall_score:.1f}/100")
print(f"   Fonte: {len(df_geo):,} eventos CVLI (tipo=cvli)")
print("="*80)
