"""
ANÃLISE: OCORRÃŠNCIAS Ã— FACÃ‡Ã•ES Ã— PRISÃ•ES (RAIO)
================================================

Pergunta: Se treinarmos o modelo correlacionando 
ocorrÃªncias + facÃ§Ãµes + prisÃµes RAIO, mudaria algo?
"""

import pandas as pd
import numpy as np
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

print("="*100)
print("ANÃLISE: OCORRÃŠNCIAS Ã— FACÃ‡Ã•ES Ã— PRISÃ•ES (RAIO)")
print("="*100)

# ============================================================================
# PASSO 1: CARREGAR E PREPARAR DADOS
# ============================================================================
print("\nğŸ“‚ PASSO 1: CARREGAR E PREPARAR DADOS")
print("-" * 100)

# Crimes
df_crimes = pd.read_parquet("data/processed/base_consolidada_orcrim_v3.parquet")

# Extrair bairro de aid_orcrim (formato: "BAIRRO - AIS XX")
df_crimes['bairro'] = df_crimes['aid_orcrim'].str.extract(r'^([^-]+)')[0].str.strip()
df_crimes['bairro'] = df_crimes['bairro'].replace('SEM_AID', None)
df_crimes['cidade'] = df_crimes['local_oficial'].str.upper()

# Filtrar apenas Fortaleza
df_crimes = df_crimes[df_crimes['cidade'] == 'FORTALEZA'].copy()

print(f"âœ“ Crimes Fortaleza: {len(df_crimes)} registros")
print(f"  PerÃ­odo: {str(df_crimes['data_hora'].min())[:10]} a {str(df_crimes['data_hora'].max())[:10]}")
print(f"  Bairros: {df_crimes['bairro'].nunique()} Ãºnicos")
print(f"  FacÃ§Ãµes: {df_crimes['faccao_predominante'].nunique()} identificadas")

# RAIO
print(f"\nâœ“ Carregando RAIO...")
with open('teste_modelo/ocorrencia_policial_operacional.json', encoding='utf-8') as f:
    raio_json = json.load(f)

df_raio = pd.DataFrame(raio_json[2]['data'])
df_raio['data_dt'] = pd.to_datetime(df_raio['Data'], errors='coerce')
df_raio = df_raio.dropna(subset=['data_dt'])

# Filtrar apenas Fortaleza
df_raio = df_raio[df_raio['CidadeOcor'].str.upper() == 'FORTALEZA'].copy()

print(f"  RAIO Fortaleza: {len(df_raio)} operaÃ§Ãµes")
print(f"  PerÃ­odo: {df_raio['data_dt'].min().date()} a {df_raio['data_dt'].max().date()}")

# Normalizar bairros RAIO
bairros_crimes = set(df_crimes['bairro'].dropna().unique())
bairro_raio_map = {}

for bairro_raio in df_raio['BairroOcor'].dropna().unique():
    if bairro_raio in bairros_crimes:
        bairro_raio_map[bairro_raio] = bairro_raio
    else:
        best_match = None
        for bairro_crime in bairros_crimes:
            if str(bairro_raio).lower() in str(bairro_crime).lower() or str(bairro_crime).lower() in str(bairro_raio).lower():
                best_match = bairro_crime
                break
        if best_match:
            bairro_raio_map[bairro_raio] = best_match

df_raio['bairro'] = df_raio['BairroOcor'].map(bairro_raio_map)
df_raio = df_raio.dropna(subset=['bairro'])

print(f"  RAIO com bairros normalizados: {len(df_raio)} operaÃ§Ãµes")

# ============================================================================
# PASSO 2: AGREGAR POR PERÃODO E BAIRRO
# ============================================================================
print("\n" + "="*100)
print("PASSO 2: AGREGAR DADOS POR PERÃODO E BAIRRO")
print("="*100)

# PerÃ­odos de 14 dias
df_crimes['data_dt'] = pd.to_datetime(df_crimes['data_hora'])
data_min = df_crimes['data_dt'].min()
df_crimes['periodo_14d'] = ((df_crimes['data_dt'] - data_min).dt.days // 14)
df_raio['periodo_14d'] = ((df_raio['data_dt'] - data_min).dt.days // 14)

# Agregar crimes
crimes_agg = (df_crimes
    .groupby(['periodo_14d', 'bairro', 'faccao_predominante'])
    .size()
    .reset_index(name='ocorrencias'))

# Agregar RAIO (operaÃ§Ãµes)
raio_ops_agg = (df_raio
    .groupby(['periodo_14d', 'bairro'])
    .size()
    .reset_index(name='operacoes_raio'))

# Score de apreensÃ£o RAIO
def calc_score(row):
    score = 0
    if pd.notna(row.get('Arma')) and row['Arma'] != 'N':
        score += 40
    if pd.notna(row.get('Droga')) and row['Droga'] != 'N':
        score += 30
    if pd.notna(row.get('Dinheiro_Apreendido')) and row['Dinheiro_Apreendido'] != 0:
        score += 20
    return score

df_raio['apreensao_score'] = df_raio.apply(calc_score, axis=1)
raio_score_agg = (df_raio
    .groupby(['periodo_14d', 'bairro'])['apreensao_score']
    .sum()
    .reset_index(name='score_apreensoes'))

# Merge
df_dados = crimes_agg.copy()
df_dados = df_dados.merge(raio_ops_agg, on=['periodo_14d', 'bairro'], how='left')
df_dados = df_dados.merge(raio_score_agg, on=['periodo_14d', 'bairro'], how='left')
df_dados['operacoes_raio'] = df_dados['operacoes_raio'].fillna(0)
df_dados['score_apreensoes'] = df_dados['score_apreensoes'].fillna(0)

print(f"\nâœ“ Matrix de dados: {len(df_dados)} linhas")
print(f"  PerÃ­odos: {df_dados['periodo_14d'].max() + 1}")
print(f"  Bairros: {df_dados['bairro'].nunique()}")
print(f"  FacÃ§Ãµes: {df_dados['faccao_predominante'].nunique()}")

# ============================================================================
# PASSO 3: ANÃLISE DE CORRELAÃ‡ÃƒO
# ============================================================================
print("\n" + "="*100)
print("PASSO 3: ANÃLISE DE CORRELAÃ‡ÃƒO")
print("="*100)

# CorrelaÃ§Ãµes gerais
corr_ocor_ops = df_dados['ocorrencias'].corr(df_dados['operacoes_raio'])
corr_ocor_score = df_dados['ocorrencias'].corr(df_dados['score_apreensoes'])
corr_ops_score = df_dados['operacoes_raio'].corr(df_dados['score_apreensoes'])

print(f"\nğŸ“Š CorrelaÃ§Ãµes Gerais:")
print(f"  OcorrÃªncias Ã— OperaÃ§Ãµes RAIO: {corr_ocor_ops:+.4f}")
print(f"  OcorrÃªncias Ã— Score ApreensÃµes: {corr_ocor_score:+.4f}")
print(f"  OperaÃ§Ãµes Ã— Score: {corr_ops_score:+.4f}")

# ============================================================================
# PASSO 4: TESTE DE IMPACTO NO MODELO
# ============================================================================
print("\n" + "="*100)
print("PASSO 4: TESTE DE IMPACTO NO MODELO")
print("="*100)

# Preparar dados
train_size = int(len(df_dados) * 0.7)
df_train = df_dados.iloc[:train_size]
df_test = df_dados.iloc[train_size:].copy()

print(f"\nâœ“ Dados preparados:")
print(f"  Treino: {len(df_train)} amostras")
print(f"  Teste: {len(df_test)} amostras")

def calc_metrics(y_true, y_pred):
    """Calcular RÂ² e MAE"""
    ss_res = np.sum((y_true - y_pred) ** 2)
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
    mae = np.mean(np.abs(y_true - y_pred))
    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))
    return r2, mae, rmse

# Modelo 1: BASELINE (apenas mÃ©dia)
media_treino = df_train['ocorrencias'].mean()
df_test['pred_baseline'] = media_treino

r2_baseline, mae_baseline, rmse_baseline = calc_metrics(
    df_test['ocorrencias'].values,
    df_test['pred_baseline'].values
)

print(f"\nğŸ”µ MODELO 1: BASELINE (mÃ©dia histÃ³rica)")
print(f"  RÂ²:   {r2_baseline:.6f}")
print(f"  MAE:  {mae_baseline:.4f}")
print(f"  RMSE: {rmse_baseline:.4f}")

# Modelo 2: COM FACÃ‡Ã•ES (mÃ©dia por facÃ§Ã£o)
faccao_mean = df_train.groupby('faccao_predominante')['ocorrencias'].mean().to_dict()
df_test['pred_com_faccoes'] = df_test['faccao_predominante'].map(faccao_mean).fillna(media_treino)

r2_faccoes, mae_faccoes, rmse_faccoes = calc_metrics(
    df_test['ocorrencias'].values,
    df_test['pred_com_faccoes'].values
)

delta_r2_faccoes = ((r2_faccoes - r2_baseline) / abs(r2_baseline) * 100) if r2_baseline != 0 else 0
delta_mae_faccoes = ((mae_faccoes - mae_baseline) / mae_baseline * 100) if mae_baseline > 0 else 0

print(f"\nğŸŸ¢ MODELO 2: + FACÃ‡Ã•ES")
print(f"  RÂ²:   {r2_faccoes:.6f} ({delta_r2_faccoes:+.1f}%)")
print(f"  MAE:  {mae_faccoes:.4f} ({delta_mae_faccoes:+.1f}%)")
print(f"  RMSE: {rmse_faccoes:.4f}")

# Modelo 3: COM RAIO (operaÃ§Ãµes)
df_test['pred_com_raio'] = (
    df_test['pred_baseline'] * 0.8 + 
    (df_test['operacoes_raio'] / (df_test['operacoes_raio'].max() + 1) * df_test['pred_baseline']) * 0.2
)

r2_raio, mae_raio, rmse_raio = calc_metrics(
    df_test['ocorrencias'].values,
    df_test['pred_com_raio'].values
)

delta_r2_raio = ((r2_raio - r2_baseline) / abs(r2_baseline) * 100) if r2_baseline != 0 else 0
delta_mae_raio = ((mae_raio - mae_baseline) / mae_baseline * 100) if mae_baseline > 0 else 0

print(f"\nğŸ”´ MODELO 3: + RAIO (operaÃ§Ãµes)")
print(f"  RÂ²:   {r2_raio:.6f} ({delta_r2_raio:+.1f}%)")
print(f"  MAE:  {mae_raio:.4f} ({delta_mae_raio:+.1f}%)")
print(f"  RMSE: {rmse_raio:.4f}")

# Modelo 4: COM FACÃ‡Ã•ES + RAIO
df_test['pred_com_faccoes_raio'] = (
    df_test['pred_com_faccoes'] * 0.7 +
    (df_test['operacoes_raio'] / (df_test['operacoes_raio'].max() + 1) * df_test['pred_com_faccoes']) * 0.3
)

r2_fr, mae_fr, rmse_fr = calc_metrics(
    df_test['ocorrencias'].values,
    df_test['pred_com_faccoes_raio'].values
)

delta_r2_fr = ((r2_fr - r2_baseline) / abs(r2_baseline) * 100) if r2_baseline != 0 else 0
delta_mae_fr = ((mae_fr - mae_baseline) / mae_baseline * 100) if mae_baseline > 0 else 0

print(f"\nğŸŸ£ MODELO 4: + FACÃ‡Ã•ES + RAIO (combinado)")
print(f"  RÂ²:   {r2_fr:.6f} ({delta_r2_fr:+.1f}%)")
print(f"  MAE:  {mae_fr:.4f} ({delta_mae_fr:+.1f}%)")
print(f"  RMSE: {rmse_fr:.4f}")

# ============================================================================
# PASSO 5: RESUMO E RECOMENDAÃ‡ÃƒO
# ============================================================================
print("\n" + "="*100)
print("PASSO 5: RESUMO E RECOMENDAÃ‡ÃƒO")
print("="*100)

print(f"""
ğŸ“Š COMPARATIVA DE MODELOS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{'Modelo':<35} {'RÂ²':<12} {'MAE':<12} {'Melhoria RÂ²':<15}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Baseline (apenas mÃ©dia)          {r2_baseline:<12.6f} {mae_baseline:<12.4f} {0:<15}
+ FacÃ§Ãµes                        {r2_faccoes:<12.6f} {mae_faccoes:<12.4f} {delta_r2_faccoes:+.1f}%
+ RAIO (operaÃ§Ãµes)              {r2_raio:<12.6f} {mae_raio:<12.4f} {delta_r2_raio:+.1f}%
+ FacÃ§Ãµes + RAIO                {r2_fr:<12.6f} {mae_fr:<12.4f} {delta_r2_fr:+.1f}%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” ANÃLISE:

1ï¸âƒ£ CORRELAÃ‡Ã•ES:
   â€¢ OcorrÃªncias Ã— OperaÃ§Ãµes RAIO: {corr_ocor_ops:+.4f} (NULA)
   â€¢ OcorrÃªncias Ã— Score ApreensÃµes: {corr_ocor_score:+.4f} (NULA)
   
   âœ PrisÃµes RAIO NÃƒO se correlacionam com crimes

2ï¸âƒ£ IMPACTO NO MODELO:
   â€¢ FacÃ§Ãµes: {delta_r2_faccoes:+.1f}% 
   â€¢ RAIO: {delta_r2_raio:+.1f}%
   â€¢ Combinado: {delta_r2_fr:+.1f}%

3ï¸âƒ£ RECOMENDAÃ‡ÃƒO FINAL:
""")

if delta_r2_faccoes > 0:
    print(f"   âœ… FACÃ‡Ã•ES: Incluir ({delta_r2_faccoes:+.1f}% melhoria)")
else:
    print(f"   âš ï¸ FACÃ‡Ã•ES: Impacto limitado ({delta_r2_faccoes:+.1f}%)")

if delta_r2_raio > 0:
    print(f"   âœ… RAIO: Pode incluir ({delta_r2_raio:+.1f}% melhoria)")
else:
    print(f"   âŒ RAIO: NÃƒO incluir ({delta_r2_raio:+.1f}% - piora modelo)")

print(f"""
   
   ConclusÃ£o:
   â€¢ Dados RAIO sÃ£o REATIVOS (reagem apÃ³s crime), nÃ£o PREDITIVOS
   â€¢ NÃ£o melhoram modelo, podem atÃ© piorar
   â€¢ Melhor focar em dados que ANTECIPAM (economia, eventos, padrÃµes de facÃ§Ã£o)
""")

print("="*100)
