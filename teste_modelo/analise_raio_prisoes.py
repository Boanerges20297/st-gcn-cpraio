"""
ANÃLISE DE DADOS RAIO - PRISÃ•ES COMO VARIÃVEL EXÃ“GENA
=======================================================

Objetivo: Usar dados de prisÃµes RAIO como features exÃ³genas para:
  1. Testar impacto em modelo ST-GCN
  2. Correlacionar prisÃµes com crimes consolidados
  3. Analisar padrÃµes territoriais
  4. Validar eficÃ¡cia de interferÃªncia policial

Abordagem:
  - Carregar dados RAIO (prisÃµes efetuadas)
  - Agregar por bairro/perÃ­odo
  - Correlacionar com crimes
  - Testar modelo com/sem prisÃµes
  - Comparar performance
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import json
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("ANÃLISE DE DADOS RAIO - PRISÃ•ES COMO VARIÃVEL EXÃ“GENA")
print("="*80)

# ============================================================================
# PASSO 1: CARREGAR E PROCESSAR DADOS RAIO
# ============================================================================
print("\nğŸ“‚ PASSO 1: CARREGAR DADOS RAIO")
print("-" * 80)

raio_path = Path(__file__).parent.parent / "data" / "raw" / "data_with_coordinates.js"

try:
    # Ler arquivo JS
    with open(raio_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Remover "module.exports = " do inÃ­cio
    content = content.replace('module.exports = ', '').strip()
    if content.endswith(';'):
        content = content[:-1]
    
    # Parse JSON
    raio_raw = json.loads(content)
    print(f"âœ“ Dados RAIO carregados: {len(raio_raw)} operaÃ§Ãµes")
    
except Exception as e:
    print(f"âœ— Erro ao carregar RAIO: {e}")
    exit(1)

# Converter para DataFrame
df_raio = pd.DataFrame(raio_raw)
print(f"âœ“ Convertido para DataFrame: {df_raio.shape[0]} linhas, {df_raio.shape[1]} colunas")

# Converter Data
df_raio['Data'] = pd.to_datetime(df_raio['Data'])

# Info bÃ¡sico
print(f"\nğŸ“Š InformaÃ§Ãµes dos dados RAIO:")
print(f"  PerÃ­odo: {df_raio['Data'].min().date()} a {df_raio['Data'].max().date()}")
print(f"  OperaÃ§Ãµes: {len(df_raio)}")
print(f"  Bairros Ãºnicos: {df_raio['BairroOcor'].nunique()}")
print(f"  Cidades: {df_raio['CidadeOcor'].unique()}")

# ============================================================================
# PASSO 2: CARREGAR DADOS DE CRIMES CONSOLIDADOS
# ============================================================================
print("\n" + "="*80)
print("PASSO 2: CARREGAR DADOS DE CRIMES CONSOLIDADOS")
print("="*80)

crime_path = Path(__file__).parent.parent / "data" / "processed" / "base_consolidada_orcrim_v3.parquet"

try:
    df_crimes = pd.read_parquet(crime_path)
    df_crimes['data_hora'] = pd.to_datetime(df_crimes['data_hora'])
    print(f"âœ“ Crimes carregados: {len(df_crimes)} registros")
except Exception as e:
    print(f"âœ— Erro: {e}")
    exit(1)

print(f"  PerÃ­odo: {df_crimes['data_hora'].min().date()} a {df_crimes['data_hora'].max().date()}")
print(f"  Bairros Ãºnicos: {df_crimes['local_oficial'].nunique()}")

# ============================================================================
# PASSO 3: NORMALIZAR NOMES DE BAIRROS
# ============================================================================
print("\n" + "="*80)
print("PASSO 3: NORMALIZAR NOMES DE BAIRROS")
print("="*80)

# Mapa de conversÃ£o (bairros RAIO â†’ bairros consolidados)
bairros_raio = df_raio['BairroOcor'].unique()
bairros_crime = df_crimes['local_oficial'].unique()

print(f"  Bairros RAIO: {len(bairros_raio)}")
print(f"  Bairros Crimes: {len(bairros_crime)}")

# Criar mapa de normalizaÃ§Ã£o (case-insensitive match)
mapa_bairros = {}
for b_raio in bairros_raio:
    if pd.isna(b_raio):
        continue
    
    # Procurar match
    match = None
    for b_crime in bairros_crime:
        if str(b_raio).lower() == str(b_crime).lower():
            match = b_crime
            break
    
    mapa_bairros[b_raio] = match

matches = sum(1 for v in mapa_bairros.values() if v is not None)
print(f"  âœ“ Bairros com match: {matches}/{len(bairros_raio)}")

# Aplicar mapa
df_raio['bairro_normalizado'] = df_raio['BairroOcor'].map(mapa_bairros)

# Filtrar apenas operaÃ§Ãµes em bairros com match
df_raio_matched = df_raio[df_raio['bairro_normalizado'].notna()].copy()
print(f"  âœ“ OperaÃ§Ãµes RAIO em bairros conhecidos: {len(df_raio_matched)}")

# ============================================================================
# PASSO 4: AGREGAÃ‡ÃƒO DE PRISÃ•ES POR PERÃODO E BAIRRO
# ============================================================================
print("\n" + "="*80)
print("PASSO 4: AGREGAÃ‡ÃƒO DE PRISÃ•ES")
print("="*80)

df_raio_matched['data'] = df_raio_matched['Data'].dt.date

# Por bairro e data
prisoes_por_dia = df_raio_matched.groupby(['bairro_normalizado', 'data']).agg({
    'Controle': 'count',  # NÃºmero de operaÃ§Ãµes
    'FichaCiops': lambda x: (x.notna()).sum(),  # OperaÃ§Ãµes com CIOPS
}).reset_index()
prisoes_por_dia.columns = ['bairro', 'data', 'n_operacoes', 'n_com_ciops']

print(f"  âœ“ AgregaÃ§Ã£o diÃ¡ria: {len(prisoes_por_dia)} registros")

# Por bairro e perÃ­odo 14 dias
prisoes_por_dia['data'] = pd.to_datetime(prisoes_por_dia['data'])
prisoes_14d = []

for bairro in prisoes_por_dia['bairro'].unique():
    df_b = prisoes_por_dia[prisoes_por_dia['bairro'] == bairro].sort_values('data')
    
    if len(df_b) == 0:
        continue
    
    # Criar janelas 14 dias
    data_min = df_b['data'].min()
    data_max = df_b['data'].max()
    
    current = data_min
    while current <= data_max:
        end = current + timedelta(days=13)
        
        df_window = df_b[(df_b['data'] >= current) & (df_b['data'] <= end)]
        
        if len(df_window) > 0:
            prisoes_14d.append({
                'bairro': bairro,
                'data_inicio': current,
                'data_fim': end,
                'n_operacoes': df_window['n_operacoes'].sum(),
                'n_com_ciops': df_window['n_com_ciops'].sum()
            })
        
        current += timedelta(days=14)

df_prisoes_14d = pd.DataFrame(prisoes_14d)
print(f"  âœ“ Janelas 14 dias: {len(df_prisoes_14d)} observaÃ§Ãµes")
print(f"  âœ“ PerÃ­odos cobertos: {df_prisoes_14d['data_inicio'].min().date()} a {df_prisoes_14d['data_fim'].max().date()}")

# ============================================================================
# PASSO 5: CORRELAÃ‡ÃƒO PRISÃ•ES Ã— CRIMES
# ============================================================================
print("\n" + "="*80)
print("PASSO 5: CORRELAÃ‡ÃƒO PRISÃ•ES Ã— CRIMES")
print("="*80)

# Agregar crimes em 14 dias (igual ao feito antes)
df_crimes_14d = []

for bairro in df_crimes['local_oficial'].unique():
    df_b = df_crimes[df_crimes['local_oficial'] == bairro]
    df_b = df_b.copy()
    df_b['data'] = df_b['data_hora'].dt.date
    
    df_b = df_b.groupby('data').agg({
        'tipo': lambda x: (
            (x.str.lower() == 'cvli').sum(),
            (x.str.lower() == 'cvp').sum()
        )
    }).reset_index()
    
    df_b[['cvli', 'cvp']] = pd.DataFrame(df_b['tipo'].tolist(), index=df_b.index)
    df_b['total_crimes'] = df_b['cvli'] + df_b['cvp']
    df_b = df_b[['data', 'total_crimes']]
    
    # Janelas 14 dias
    df_b['data'] = pd.to_datetime(df_b['data'])
    
    data_min = df_b['data'].min()
    data_max = df_b['data'].max()
    
    current = data_min
    while current <= data_max:
        end = current + timedelta(days=13)
        
        df_window = df_b[(df_b['data'] >= current) & (df_b['data'] <= end)]
        
        if len(df_window) > 0:
            df_crimes_14d.append({
                'bairro': bairro,
                'data_inicio': current,
                'data_fim': end,
                'total_crimes': df_window['total_crimes'].sum()
            })
        
        current += timedelta(days=14)

df_crimes_14d = pd.DataFrame(df_crimes_14d)
print(f"  âœ“ Crimes em janelas 14d: {len(df_crimes_14d)} observaÃ§Ãµes")

# Mesclar dados
df_merged = pd.merge(
    df_crimes_14d,
    df_prisoes_14d,
    on=['bairro', 'data_inicio', 'data_fim'],
    how='left'
)

# Preencher NaN com 0 (sem operaÃ§Ãµes RAIO naquele perÃ­odo)
df_merged['n_operacoes'] = df_merged['n_operacoes'].fillna(0)
df_merged['n_com_ciops'] = df_merged['n_com_ciops'].fillna(0)

print(f"  âœ“ Dados mesclados: {len(df_merged)} observaÃ§Ãµes")

# CorrelaÃ§Ã£o
corr_ops_crimes = df_merged[['total_crimes', 'n_operacoes']].corr().iloc[0, 1]
corr_ciops_crimes = df_merged[['total_crimes', 'n_com_ciops']].corr().iloc[0, 1]

print(f"\nğŸ“ˆ CORRELAÃ‡ÃƒO OBSERVADA:")
print(f"  Crimes Ã— OperaÃ§Ãµes RAIO: {corr_ops_crimes:.4f}")
print(f"  Crimes Ã— CIOPS: {corr_ciops_crimes:.4f}")

# Por bairro
print(f"\n  Top 10 Bairros (por operaÃ§Ãµes):")
print(f"  {'Bairro':<25} {'Crimes':<10} {'OperaÃ§Ãµes':<12} {'Corr.':<8}")
print(f"  {'-'*55}")

bairro_summary = df_merged.groupby('bairro').agg({
    'total_crimes': 'mean',
    'n_operacoes': ['sum', 'mean'],
    'n_com_ciops': 'sum'
}).reset_index()

bairro_summary.columns = ['bairro', 'avg_crimes', 'total_ops', 'avg_ops', 'total_ciops']

# Calcular correlaÃ§Ã£o por bairro
bairro_corr = []
for bairro in df_merged['bairro'].unique():
    df_b = df_merged[df_merged['bairro'] == bairro]
    if len(df_b) > 1:
        corr = df_b[['total_crimes', 'n_operacoes']].corr().iloc[0, 1]
        bairro_corr.append({'bairro': bairro, 'corr': corr})

df_corr = pd.DataFrame(bairro_corr).sort_values('corr', ascending=False, na_position='last')

for idx, row in df_corr.head(10).iterrows():
    summary = bairro_summary[bairro_summary['bairro'] == row['bairro']].iloc[0]
    corr_val = row['corr'] if not np.isnan(row['corr']) else 0.0
    print(f"  {row['bairro']:<25} {summary['avg_crimes']:<10.1f} {summary['total_ops']:<12.0f} {corr_val:<8.3f}")

# ============================================================================
# PASSO 6: ANÃLISE DE PADRÃƒO TERRITORIAL
# ============================================================================
print("\n" + "="*80)
print("PASSO 6: ANÃLISE DE PADRÃƒO TERRITORIAL")
print("="*80)

# Agrupar operaÃ§Ãµes por bairro
operacoes_por_bairro = df_raio_matched.groupby('bairro_normalizado').agg({
    'Controle': 'count',
    'Natureza': lambda x: x.mode()[0] if len(x) > 0 else None,
    'Data': lambda x: (x.max() - x.min()).days
}).reset_index()
operacoes_por_bairro.columns = ['bairro', 'n_total', 'crime_principal', 'dias_ativo']

operacoes_por_bairro = operacoes_por_bairro.sort_values('n_total', ascending=False)

print(f"\n  Top 15 Bairros por Atividade RAIO:")
print(f"  {'Bairro':<25} {'OperaÃ§Ãµes':<12} {'Dias Ativo':<12} {'Crime Principal':<35}")
print(f"  {'-'*84}")

for idx, row in operacoes_por_bairro.head(15).iterrows():
    crime = str(row['crime_principal'])[:34] if row['crime_principal'] else "Variado"
    print(f"  {row['bairro']:<25} {row['n_total']:<12.0f} {row['dias_ativo']:<12.0f} {crime:<35}")

# ============================================================================
# PASSO 7: ANÃLISE DE TIPOS DE DELITOS RAIO
# ============================================================================
print("\n" + "="*80)
print("PASSO 7: ANÃLISE DE TIPOS DE DELITOS RAIO")
print("="*80)

# Extrair tipo principal da Natureza
natureza_counts = df_raio_matched['Natureza'].value_counts()

print(f"\n  Top 10 Tipos de OperaÃ§Ã£o:")
for idx, (natureza, count) in enumerate(natureza_counts.head(10).items(), 1):
    natureza_short = str(natureza)[:60]
    print(f"  {idx}. {natureza_short}... ({count})")

# ============================================================================
# PASSO 8: DISTRIBUIÃ‡ÃƒO TEMPORAL
# ============================================================================
print("\n" + "="*80)
print("PASSO 8: ANÃLISE TEMPORAL")
print("="*80)

df_raio_matched['ano_mes'] = df_raio_matched['Data'].dt.to_period('M')

temporal = df_raio_matched.groupby('ano_mes').size()

print(f"\n  OperaÃ§Ãµes por MÃªs (Ãºltimos 12):")
print(f"  {'PerÃ­odo':<12} {'OperaÃ§Ãµes':<12}")
print(f"  {'-'*24}")

for periodo, count in temporal.tail(12).items():
    print(f"  {str(periodo):<12} {count:<12}")

# ============================================================================
# PASSO 9: IMPACTO EM CRIME
# ============================================================================
print("\n" + "="*80)
print("PASSO 9: ANÃLISE DE IMPACTO")
print("="*80)

# Dividir bairros em com/sem operaÃ§Ãµes RAIO
bairros_com_raio = set(df_merged[df_merged['n_operacoes'] > 0]['bairro'].unique())
bairros_sem_raio = set(df_merged[df_merged['n_operacoes'] == 0]['bairro'].unique())

crimes_com_raio = df_merged[df_merged['bairro'].isin(bairros_com_raio)]['total_crimes'].mean()
crimes_sem_raio = df_merged[df_merged['bairro'].isin(bairros_sem_raio)]['total_crimes'].mean()

print(f"\n  Crimes MÃ©dios (14 dias):")
print(f"    Com operaÃ§Ãµes RAIO: {crimes_com_raio:.2f}")
print(f"    Sem operaÃ§Ãµes RAIO: {crimes_sem_raio:.2f}")
print(f"    DiferenÃ§a: {crimes_com_raio - crimes_sem_raio:+.2f} ({((crimes_com_raio - crimes_sem_raio)/crimes_sem_raio * 100):+.1f}%)")

# AnÃ¡lise antes/depois por bairro
print(f"\n  AnÃ¡lise Antes/Depois para bairros com mÃºltiplas operaÃ§Ãµes:")
print(f"  {'Bairro':<25} {'Antes (mÃ©dia)':<15} {'Depois (mÃ©dia)':<15} {'MudanÃ§a':<12}")
print(f"  {'-'*67}")

for bairro in bairros_com_raio:
    df_b = df_merged[df_merged['bairro'] == bairro].sort_values('data_inicio')
    
    if len(df_b) < 4:  # Precisar de pelo menos 4 perÃ­odos
        continue
    
    # Primeiro perÃ­odo
    antes = df_b.iloc[0]['total_crimes']
    # Ãšltimo perÃ­odo
    depois = df_b.iloc[-1]['total_crimes']
    mudanca = depois - antes
    
    if len(str(bairro)) < 25:
        print(f"  {bairro:<25} {antes:<15.1f} {depois:<15.1f} {mudanca:+12.1f}")

# ============================================================================
# PASSO 10: EXPORTAR RELATÃ“RIO
# ============================================================================
print("\n" + "="*80)
print("PASSO 10: EXPORTAR RELATÃ“RIO")
print("="*80)

relatorio = {
    "titulo": "AnÃ¡lise de Dados RAIO - PrisÃµes como VariÃ¡vel ExÃ³gena",
    "data": datetime.now().isoformat(),
    "dados_raio": {
        "total_operacoes": len(df_raio),
        "operacoes_matched": len(df_raio_matched),
        "periodo": {
            "inicio": str(df_raio['Data'].min().date()),
            "fim": str(df_raio['Data'].max().date())
        },
        "bairros_unicos": df_raio['BairroOcor'].nunique(),
        "bairros_matched": len(bairros_raio)
    },
    "correlacao": {
        "crimes_vs_operacoes": round(corr_ops_crimes, 4),
        "crimes_vs_ciops": round(corr_ciops_crimes, 4),
        "interpretacao": "CorrelaÃ§Ã£o positiva indica: Mais operaÃ§Ãµes em Ã¡reas com mais crimes" if corr_ops_crimes > 0.3 else "CorrelaÃ§Ã£o fraca/negativa"
    },
    "impacto": {
        "crimes_medio_com_raio": round(crimes_com_raio, 2),
        "crimes_medio_sem_raio": round(crimes_sem_raio, 2),
        "diferenca_percentual": round((crimes_com_raio - crimes_sem_raio)/crimes_sem_raio * 100, 1)
    },
    "top_bairros": operacoes_por_bairro.head(10).to_dict('records'),
    "recomendacoes": {
        "modelo_com_exogenas": "Incluir n_operacoes e n_com_ciops como features",
        "esperado_r2": "0.81 â†’ 0.85+ (melhoria esperada 0.04+)",
        "proximo_passo": "Testar ST-GCN com features exÃ³genas"
    }
}

# Adicionar estatÃ­sticas por bairro
relatorio['bairro_stats'] = df_corr.head(10).to_dict('records')

output_path = Path(__file__).parent / "analise_raio_prisoes.json"
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(relatorio, f, indent=2, ensure_ascii=False)

print(f"\nâœ“ RelatÃ³rio salvo: {output_path}")

# ============================================================================
# VISUALIZAÃ‡ÃƒO FINAL
# ============================================================================
print("\n" + "="*80)
print("RESUMO VISUAL")
print("="*80)

print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ANÃLISE DE DADOS RAIO - PRISÃ•ES EXÃ“GENAS              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚ DADOS COLETADOS:                                               â”‚
â”‚   OperaÃ§Ãµes RAIO: {len(df_raio_matched):<35}      â”‚
â”‚   Bairros covered: {len(bairros_com_raio):<35}      â”‚
â”‚   PerÃ­odo: {str(df_raio['Data'].min().date()):<35}      â”‚
â”‚           a {str(df_raio['Data'].max().date()):<35}      â”‚
â”‚                                                                â”‚
â”‚ CORRELAÃ‡ÃƒO OBSERVADA:                                          â”‚
â”‚   Crimes Ã— OperaÃ§Ãµes: {corr_ops_crimes:+7.4f}                   â”‚
â”‚   Crimes Ã— CIOPS: {corr_ciops_crimes:+7.4f}                     â”‚
â”‚                                                                â”‚
â”‚ IMPACTO TERRITORIAL:                                           â”‚
â”‚   Bairros com RAIO (mÃ©dia): {crimes_com_raio:>6.1f} crimes/14d  â”‚
â”‚   Bairros sem RAIO (mÃ©dia): {crimes_sem_raio:>6.1f} crimes/14d  â”‚
â”‚   DiferenÃ§a: {crimes_com_raio - crimes_sem_raio:+6.1f} ({((crimes_com_raio - crimes_sem_raio)/crimes_sem_raio * 100):+.1f}%)                 â”‚
â”‚                                                                â”‚
â”‚ PRÃ“XIMOS PASSOS:                                               â”‚
â”‚   1. Incorporar n_operacoes como feature exÃ³gena              â”‚
â”‚   2. Treinar modelo ST-GCN com dados exÃ³genos                 â”‚
â”‚   3. Comparar RÂ² com/sem variÃ¡vel exÃ³gena                     â”‚
â”‚   4. Validar se prisÃµes melhoram previsÃ£o                     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

print("="*80)
print("âœ“ ANÃLISE CONCLUÃDA")
print("="*80)
