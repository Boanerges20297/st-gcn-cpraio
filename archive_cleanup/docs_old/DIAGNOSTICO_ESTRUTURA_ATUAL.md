# üîç DIAGN√ìSTICO: ESTRUTURA ATUAL DO PROJETO

**Data:** 21 de Janeiro de 2026  
**Status:** An√°lise de Compatibilidade com Plano de Integra√ß√£o

---

## 1. ESTRUTURA DE C√ìDIGO ATUAL

### 1.1 Componentes Existentes

| Arquivo | Linhas | Fun√ß√£o | Estado |
|---------|--------|--------|--------|
| `src/model.py` | 90+ | STGCN_Cpraio com LSTM + GCN | ‚úÖ Pronto |
| `src/exogenous.py` | 165 | Dados ex√≥genos (INMET, feriados, crime score) | ‚ö†Ô∏è Parcial |
| `src/data_loader.py` | 720 | Carregamento dados brutos | ‚úÖ Robusto |
| `src/graph_builder.py` | ? | Constru√ß√£o de grafo | ‚ùì A validar |
| `src/trainer.py` | ? | Loop de treinamento | ‚ùì A validar |
| `src/predict.py` | ? | Infer√™ncia | ‚ùì A validar |

### 1.2 Arquitetura ST-GCN Atual

```
forward(x, edge_index):
  INPUT:
    - x: (batch, seq_len, nodes, features) ou (batch, nodes, features)
    - edge_index: (2, num_edges)  [formato PyTorch Geometric]
  
  PROCESSAMENTO:
    1. LSTM por n√≥: (seq_len, features) ‚Üí hidden_channels
    2. GCN 2 camadas: propaga√ß√£o espacial
    3. FC head: hidden_channels ‚Üí 3 classes (AUMENTO/DIMINUI√á√ÉO/EST√ÅVEL)
  
  OUTPUT:
    - (batch, nodes, 3)
```

**Status:** ‚úÖ Compat√≠vel com atualiza√ß√£o din√¢mica de edge_index

---

## 2. DADOS EX√ìGENOS ATUAIS

### 2.1 O que `exogenous.py` Oferece

```python
# Fun√ß√µes atuais:

1. load_inmet_aggregated()
   - Entrada: CSV de esta√ß√µes meteorol√≥gicas
   - Sa√≠da: DataFrame agregado por (date, node)
   - Vari√°veis: precipita√ß√£o, temperatura
   
2. holidays_series()
   - Entrada: lista de datas
   - Sa√≠da: dict date -> 0/1 (feriado ou n√£o)
   
3. [Inferido] crime_score_features()
   - Entrada: crime dataset
   - Sa√≠da: features temporais de crimes
```

**Status:** ‚ö†Ô∏è Preparado para m√∫ltiplos ex√≥genos, mas **SEM dados de pris√µes**

---

## 3. DADOS DE PRIS√ïES DISPON√çVEIS

### 3.1 Fonte

```
Arquivo: data/raw/ocorrencia_policial_operacional.json
Registros: 9.069 opera√ß√µes
Per√≠odo: 2025-01-01 at√© hoje
Campos: Controle, Data, HoraI, BairroOcor, lat_long, Natureza, 
        area_faccao, total_drogas_cache, total_armas_cache, Dinheiro_Apreendido
```

**Status:** ‚úÖ JSON v√°lido, ready for integration

### 3.2 Mapeamento de Campos

```
JSON Campo           ‚Üí Uso Proposto
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Data                 ‚Üí temporal aggregation
BairroOcor           ‚Üí spatial join
total_drogas_cache   ‚Üí operacoes_intensidade
total_armas_cache    ‚Üí operacoes_risco
Dinheiro_Apreendido  ‚Üí operacoes_escala
area_faccao          ‚Üí target indicator (CV/PCC/GDE)
```

---

## 4. GAPS IDENTIFICADOS

### 4.1 Normaliza√ß√£o de Pris√µes

**Problema:** JSON de pris√µes NOT normalizado em pipeline.

**Solu√ß√£o Necess√°ria:**
- [ ] Criar `src/data/operations_loader.py` (carregar JSON)
- [ ] Criar `src/data/operations_normalizer.py` (MinMax, temporal agg)
- [ ] Output: `data/processed/prisoes_normalized.parquet`

**Criticidade:** ALTA (blockage)

### 4.2 Engenharia de Features Ex√≥genas

**Problema:** `exogenous.py` N√ÉO inclui features de pris√µes.

**Solu√ß√£o Necess√°ria:**
- [ ] Estender `exogenous.py` com `compute_operations_features()`
- [ ] Computar: lag_7d, lag_30d, drogas_norm, armas_norm, dias_desde_op, etc.
- [ ] Output: `data/processed/prisoes_features_exogenous.parquet`

**Criticidade:** ALTA (blockage)

### 4.3 Atualiza√ß√£o Din√¢mica de Graph

**Problema:** `model.py` aceita `edge_index` est√°tico.

**Solu√ß√£o Necess√°ria:**
- [ ] Criar fun√ß√£o `compute_dynamic_edge_index()` que modifica pesos baseado em opera√ß√µes
- [ ] Integrar em `trainer.py` para chamada por batch/per√≠odo
- [ ] Modificar forward() para aceitar `edge_weights` din√¢mica

**Criticidade:** ALTA (core feature)

### 4.4 API para Tempo Real

**Problema:** Dashboard externo precisa enviar dados diariamente.

**Solu√ß√£o Necess√°ria:**
- [ ] Criar endpoint `/api/update-operations` em `src/app.py`
- [ ] Valida√ß√£o de input, armazenamento em `operations_data.json`
- [ ] Trigger de recompute de features + retrainamento (opcional)

**Criticidade:** M√âDIA (nice to have, pode ser semanal)

---

## 5. PLANO DE IMPLEMENTA√á√ÉO (DETALHADO)

### Fase 1: Normaliza√ß√£o (16 horas)

```
ARQUIVO NOVO: src/data/operations_loader.py (150 linhas)
ARQUIVO NOVO: src/data/operations_normalizer.py (200 linhas)

Fluxo:
  1. operations_loader.load_json(path)
     ‚îî‚îÄ Valida 9.069 registros
     ‚îî‚îÄ Converte types (Data ‚Üí datetime, drogas ‚Üí float)
     ‚îî‚îÄ Output: df com 10 colunas (Controle, Data, BairroOcor, etc.)
  
  2. operations_normalizer.normalize(df)
     ‚îî‚îÄ MinMax scaling drogas/armas/dinheiro
     ‚îî‚îÄ Agrega√ß√£o temporal (di√°ria)
     ‚îî‚îÄ Mapeamento BairroOcor ‚Üí bairro_id (0-387)
     ‚îî‚îÄ Output: parquet com (bairro_id, data, drogas_norm, armas_norm, ...)
     
Teste:
  ‚úÖ 9.069 registros carregados
  ‚úÖ Nenhum NaN
  ‚úÖ Todos valores em [0, 1]
  ‚úÖ Bairros mape√°veis (todas as 388 IDs)
```

### Fase 2: Features Ex√≥genas (12 horas)

```
ARQUIVO MODIFICADO: src/exogenous.py (+ 150 linhas)

Fun√ß√£o NOVA: compute_operations_features(df_normalized)
  
  Entrada: parquet normalizado de pris√µes
  
  Sa√≠da: DataFrame com 8+ features
    - operacoes_7d: sum de opera√ß√µes √∫ltimos 7 dias
    - operacoes_30d: sum de opera√ß√µes √∫ltimos 30 dias
    - drogas_apreendidas_7d_norm: soma drogas [0,1]
    - armas_apreendidas_7d_norm: soma armas [0,1]
    - dias_desde_ultima_operacao: dias desde √∫ltima op
    - intensidade_operacional_7d: combina√ß√£o ponderada
    - faccao_CV_7d, faccao_PCC_7d, faccao_GDE_7d: one-hot
    - impacto_prisoes_esperado: feature s√≠ntese

Teste:
  ‚úÖ 8+ features calculadas
  ‚úÖ Correla√ß√£o com crimes > 0.4
  ‚úÖ Sem colinearidade (VIF < 5)
  ‚úÖ Temporal windows funcionam (lag_7d < lag_30d)
```

### Fase 3: Graph Din√¢mico (14 horas)

```
ARQUIVO NOVO: src/models/dynamic_graph.py (250 linhas)

Fun√ß√£o NOVA: compute_dynamic_edge_index(
  A_base: scipy sparse,
  operations_features: pd.DataFrame,
  bairro_id,
  timestamp,
  decay_factor=0.9
)

  Entrada:
    - A_base: adjacency matrix est√°tica (388 x 388)
    - operations_features: features agregadas por (bairro, date)
    - timestamp: per√≠odo atual
  
  Sa√≠da:
    - edge_index_updated: PyTorch tensor (2, num_edges)
    - edge_weight_updated: PyTorch tensor (num_edges,)
  
  L√≥gica:
    - Para cada bairro i, calcular impacto = f(operacoes)
    - Multiplicar A_base[i,j] por impacto[j]
    - Aplicar decay temporal
    - Retornar edge_index + edge_weights normalizados

Teste:
  ‚úÖ Com ops alta ‚Üí edge_weights aumentam (~1.2x)
  ‚úÖ Sem ops ‚Üí edge_weights ‚âà baseline
  ‚úÖ Decay reduz efeito ao longo dos dias
  ‚úÖ Grafo mant√©m conectividade (rank n√£o cai)
```

### Fase 4: Integra√ß√£o no ST-GCN (10 horas)

```
ARQUIVO MODIFICADO: src/model.py (+ 50 linhas)

Modifica√ß√£o 1: forward() aceita edge_weight opcional
  
  Antes:
    def forward(self, x, edge_index)
    
  Depois:
    def forward(self, x, edge_index, edge_weight=None)
    
  Uso: self.gcn1(h_slice, edge_index, edge_weight)

Modifica√ß√£o 2: trainer.py computa A(t) din√¢mica

  Em cada batch/per√≠odo:
    1. Carregar operations_features para per√≠odo T
    2. Computar edge_weight_dynamic = compute_dynamic_edge_index(...)
    3. Passar para forward() com edge_weight din√¢mica
    4. Backprop normal

Teste:
  ‚úÖ Model outputs diferente com/sem edge_weight
  ‚úÖ Correla√ß√£o com opera√ß√µes > 0.6
  ‚úÖ Sem erros de dimens√£o
  ‚úÖ Training loss converge
```

### Fase 5: Retrainamento (10 horas)

```
ARQUIVO MODIFICADO: src/trainer.py (+ 30 linhas)

Modifica√ß√£o: Integrar dados de pris√µes no loop

  for epoch in range(epochs):
    for batch in train_loader:
      # Dados criminais
      x, y = batch  # (batch, seq, nodes, features), (batch, nodes, 3)
      
      # NOVO: Dados de pris√µes
      timestamp = get_timestamp(batch)
      ops_features = operations_features.loc[timestamp]
      edge_weight_dynamic = compute_dynamic_edge_index(..., timestamp)
      
      # Forward com edge_weight din√¢mica
      y_pred = model(x, edge_index, edge_weight_dynamic)
      
      # Loss + Backward
      loss = criterion(y_pred, y)
      loss.backward()
      optimizer.step()

Teste:
  ‚úÖ Training com dados antigos (2022-2024)
  ‚úÖ Valida√ß√£o em 2025 com opera√ß√µes conhecidas
  ‚úÖ Accuracy >= 28% (vs 14% antigo)
  ‚úÖ F1 >= 25% (vs 8.6% antigo)
```

### Fase 6: Cleanup (4 horas)

```
Remover:
  ‚ùå data/models/stgcn_v2_trained.pt (vers√£o antiga)
  ‚ùå Qualquer modelo sem exogenous
  
Criar:
  ‚úÖ data/models/stgcn_v1_with_exogenous.pt (novo)
  ‚úÖ data/models/metadata_v1.json (specifications)
```

---

## 6. CRIT√âRIO DE SUCESSO

### 6.1 Normaliza√ß√£o

- [x] 100% dos 9.069 registros carregados
- [x] Nenhum NaN no output
- [x] Todos valores ex√≥genos em [0, 1]
- [x] Bairros mape√°veis (100% match com 388 IDs)

### 6.2 Features

- [x] 8+ features ex√≥genas calculadas
- [x] Correla√ß√£o com crimes > 0.4
- [x] VIF < 5 (sem colinearidade)
- [x] Temporal windows coerentes (7d < 30d)

### 6.3 Graph

- [x] A(t) reflete opera√ß√µes (+10% a +50% boost)
- [x] Sem desconex√£o (rank preservado)
- [x] Decay funciona (efeito decresce com dias)

### 6.4 Modelo

- [x] **Accuracy >= 28%** (vs 14% antigo) ‚Üí **2x melhoria**
- [x] **F1 >= 25%** (vs 8.6% antigo) ‚Üí **3x melhoria**
- [x] Correla√ß√£o com opera√ß√µes > 0.7
- [x] Confian√ßa correlacionada com impacto ops

---

## 7. TIMELINE REALISTA

```
Seg 21 (hoje): Criar plano + diagnosticar estrutura ‚Üê AQUI
Ter 22-Qua 23: Fase 1 (Normaliza√ß√£o) + Fase 2 (Features)
Qui 24-Sex 25: Fase 3 (Graph) + Fase 4 (Integra√ß√£o)
Seg 28: Fase 5 (Retrainamento) + Fase 6 (Cleanup)
Ter 29: Valida√ß√£o end-to-end + documenta√ß√£o

Total: ~5-6 dias de trabalho concentrado
```

---

## 8. BLOQUEADORES E DEPEND√äNCIAS

### N√£o h√° bloqueadores t√©cnicos
- ‚úÖ JSON de pris√µes est√° pronto
- ‚úÖ Arquitetura ST-GCN √© extens√≠vel
- ‚úÖ Dados crimes existem (2022-2024)
- ‚úÖ Infraestrutura de processamento present

### Depend√™ncias Criticas
1. **Mapeamento Bairro ‚Üí ID:** Validar que os 388 bairros podem ser mapeados do JSON
2. **Adjacency Matrix Base:** Localizar e carregar A_base (est√°tica)
3. **Dataset de Crimes 2025:** Confirmar que valida√ß√£o de 2025 tem timestamps corretos

---

## ‚úÖ PR√ìXIMOS PASSOS

**Aguardando aprova√ß√£o do user para:**

1. **Iniciar Fase 1 (Normaliza√ß√£o)** - Criar `operations_loader.py` e `operations_normalizer.py`
2. **Executar testes de valida√ß√£o** - Confirmar 9.069 registros carregados corretamente
3. **Proceder com Fase 2-6** - Engenharia de features at√© retrainamento

**Documento refer√™ncia:** `PLANO_INTEGRACAO_DADOS_EXOGENOS_V1.md`

---

**Status Final:** üü¢ **PRONTO PARA IMPLEMENTA√á√ÉO**

Todas as depend√™ncias t√©cnicas est√£o presentes. Faltam apenas os scripts de normaliza√ß√£o e engenharia de features (boilerplate estilo).

